{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for CCA21 Project\n",
    "# Working with El Corpus del Español\n",
    "\n",
    "This notebook creates the pipeline to do the text preprocesing steps for:\n",
    "\n",
    "1. Topic Models\n",
    "2. Dynamic Topic Models\n",
    "3. Word2Vec\n",
    "4. Diachronic Word Embeddings\n",
    "\n",
    "`1` and `2` require the data in a different format from `3` and `4`. \n",
    "\n",
    "Notebook index:\n",
    "1. Libraries\n",
    "2. Helper functions\n",
    "3. Pipeline\n",
    "4. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zipfile\n",
    "import os\n",
    "import sys\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadcorpus(corpus_name, corpus_style=\"text\"):\n",
    "    '''\n",
    "    Iterates through the files in the folder, and \n",
    "    unzips the files, storing them in a dictionary with \n",
    "    each zip file mapping to a list of the texts.\n",
    "    \n",
    "    Input:\n",
    "        corpus_name (str): indicates the working directory and the name\n",
    "                        of the foldet that contains the corpus\n",
    "\n",
    "    Output:\n",
    "        text_raw (dict):\n",
    "            key - name of the enclosing folder\n",
    "            value - string that corresponds to that folder\n",
    "    '''\n",
    "    texts_raw = {}\n",
    "    for file in os.listdir(corpus_name + \"/\"):\n",
    "        if corpus_style in file:\n",
    "            print(file)\n",
    "            zfile = zipfile.ZipFile(corpus_name + \"/\" + file)\n",
    "            for file in zfile.namelist():\n",
    "                texts_raw[file] = []\n",
    "                with zfile.open(file) as f:\n",
    "                    for line in f:\n",
    "                        texts_raw[file].append(line)\n",
    "    return texts_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_sources(corpus_name, source_name):\n",
    "    '''\n",
    "    Returns list of the sources (websites) the text comes from source_name\n",
    "    \n",
    "    Input:\n",
    "        corpus_name (str)\n",
    "        source_name (str)\n",
    "    \n",
    "    Output:\n",
    "        list_source_name (list)\n",
    "    '''\n",
    "    zfile = zipfile.ZipFile(corpus_name + \"/\" + source_name)\n",
    "    list_source_name = []\n",
    "\n",
    "    for file in zfile.namelist():\n",
    "        with zfile.open(file) as f:\n",
    "            for line in f:\n",
    "                list_source_name.append(line)\n",
    "\n",
    "    return list_source_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_text(raw_texts):\n",
    "    '''\n",
    "    Decodes and removes some reg expresssions from text\n",
    "    Reg expressions removed: [¡!@#$:);,¿?&]\n",
    "    Notice that I don't remove dots (.) to be able to mark sentences\n",
    "    \n",
    "    Input:\n",
    "        raw_texts (str): text\n",
    "\n",
    "    \n",
    "    Output:\n",
    "        clean text(list): list with clean texts\n",
    "        \n",
    "    '''\n",
    "    clean_texts = []\n",
    "    for text in raw_texts:\n",
    "        try:\n",
    "            text = text.decode(\"utf-8\")\n",
    "            text = re.sub('[¡!@#$:);,¿?&]', '', text)\n",
    "            clean_texts.append(text)\n",
    "        except AttributeError:\n",
    "            print(\"ERROR CLEANING\", \"Text:\")\n",
    "            print(text)\n",
    "            continue\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Unicode Error, Skip\")\n",
    "            continue\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_match_key_text(raw_dic_texts, max_num_loops, max_texts, max_onetext_length):\n",
    "    '''\n",
    "    Creates dictionary of text to match text and sources\n",
    "    \n",
    "    Input:\n",
    "        raw_dic_texts (dict):\n",
    "            key - name of the enclosing folder\n",
    "            value - string that corresponds to that folder\n",
    "\n",
    "        max_num_loops(int): number that determines the overall\n",
    "                             number of loops\n",
    "        \n",
    "        max_texts(int): number that detemines the number of texts \n",
    "                        included in the list\n",
    "        \n",
    "        max_onetext_length(int): number that blocks larger than\n",
    "                                 n character texts\n",
    "        \n",
    "\n",
    "    Output:\n",
    "        websites_text(dict):\n",
    "            key - id that matches the text and the source\n",
    "            value - (str) text\n",
    "    '''\n",
    "    websites_text = {}\n",
    "    i=0\n",
    "    \n",
    "    for key in raw_dic_texts:\n",
    "        i =+ 1\n",
    "\n",
    "        if len(websites_text) > max_texts:\n",
    "            break\n",
    "        texts_for_key = clean_raw_text(raw_dic_texts[key])\n",
    "        for one_text in texts_for_key:\n",
    "            if len(one_text) >= max_onetext_length:\n",
    "                break\n",
    "            key_text = one_text.split()[0]\n",
    "            try:\n",
    "                websites_text[key_text] = one_text[7:]\n",
    "            except IndexError:\n",
    "                continue\n",
    "        if i==max_num_loops:\n",
    "                break\n",
    "    return websites_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_text_sources(source_list, websites_text, span_df, max_num_loops):\n",
    "    '''\n",
    "    Merges the list of sources and the text comming from those sources \n",
    "    into a pandas dataframe\n",
    "    \n",
    "    Input:\n",
    "        source_list (list): list of url sources \n",
    "        websites_text (dict): \n",
    "            key (int)- id to source\n",
    "            value (str)- text \n",
    "        span_df (pandas dr): pandas dataframe that has only the maes of the columns\n",
    "        max_num_loops (int): number to break the loop and get smaller \n",
    "                             pandas dataframes\n",
    "                             \n",
    "    Output:\n",
    "        \n",
    "    '''\n",
    "    i = 0\n",
    "    for website in source_list[3:]:\n",
    "        '''\n",
    "        Loops over the list of url sources\n",
    "        '''\n",
    "        i =+ 1\n",
    "        try:\n",
    "            textID, Number_of_words, Genre, Country, \\\n",
    "                Website, URL, Title = website.decode(\"utf-8\").split(\"\\t\")\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        try:\n",
    "            span_df.loc[textID.strip()] = \\\n",
    "                        [Title.strip(), Genre.strip(), Country.strip(), \n",
    "                        Website.strip(), URL.strip(), Number_of_words.strip(),  \n",
    "                        websites_text[textID.strip()]]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if i==max_num_loops:\n",
    "            break\n",
    "        \n",
    "        return span_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_span['MX-B-0.txt'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'747390 10 Actividades que sirven para bajar de peso 1 0 Actividades que sirven para bajar de peso  Si quieres bajar de peso pero no te gusta hacer ejercicio  es momento que practiques algunas actividades para quemar calorías de forma divertida y sin que sientas el esfuerzo que realizas  De acuerdo con información publicada en mother nature network ( mnn   el número de calorías que el cuerpo elimina depende de factores como edad  peso  sexo y actividades  Nuestro organismo utiliza las calorías como energía para realizar todas sus funciones desde la digestión hasta generar pensamientos  sin embargo  para prevenir el sobrepeso  necesitamos realizar actividades vigorosas y divertidas   Quema 300 calorías  Las siguientes actividades te ayudarán a quemar hasta 300 calorías en sólo algunos minutos  Conócelas y aprovecha para practicar las en estas vacaciones de verano  1  Jugar frisbee  Lo ideal es que lo practiques durante 80 minutos  ya sea en la playa o en un día de campo  Además  te ayudará a convivir en familia  2            minutos  lograrás eliminar la grasa que se acumula en tu cuerpo  3  Montar a caballo  Disfruta de el paisaje en compañía de este animal durante 60 minutos  Fortalecerás el abdomen y quemarás grasa  4  Camina  Si lo haces a un mismo ritmo durante 60 minutos  gozarás de una mejor salud cardiovascular y mantendrás un cuerpo esbelto  Hazlo con compañía y relája te con una buena conversación  5  Plantación de árboles  Cuida el medio ambiente y lleva a tu familia a plantar algunos árboles   A el hacer lo durante 54 minutos quemarás 300 calorías  6  Bádminton  Juega durante 54 minutos y tonifica todo tu cuerpo  No te darás cuenta de todo el esfuerzo que realizas  7  Juega con tus hijos  No necesitas nada para disfrutar la compañía de tus hijos en un parque o en el patio de tu casa  Disfruta 48 minutos sin descanso con ellos  9  Golf  Aunque no lo creas  esta actividad fomenta la pérdida de peso  sobre todo  si           a cada hoyo durante 44 minutos  10  Patinaje  Hazlo en un parque o en alguna pista durante 35 minutos  es una forma más segura y te concentrarás en tus pensamientos  Además  diversos estudios sugieren que practicar una actividad a el aire libre lleva de vitalidad  entusiasmo  placer y autoestima a las personas  porque se favorece el desarrollo de endorfinas para reducir el estrés y la fatiga   Anímate y pon te en forma mientras te diviertes  Acerca de Yei Evolution Mi Nombre es Yeriel Vélez  soy un blogger a el que le encanta el Béisbol  la música  la publicadad y el Marketing  soy estudiante de administración  Contacto  elrankiao56hotmailcom Sigueme en Twitter / Facebook \\r\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = raw_span['MX-B-0.txt'][0]\n",
    "test1_re = test1.decode(\"utf-8\")\n",
    "test1_re = re.sub('[¡!@#$:).;,¿?&]', '', test1_re)\n",
    "#test1_re = re.sub(\"\\d+\", \"\", test1_re)\n",
    "test1_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'747390'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_re\n",
    "first_word = test1_re.split()[0]\n",
    "first_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_EC-jss.zip\n",
      "text_CU-rag.zip\n",
      "text_MX-vzo.zip\n",
      "text_AR-tez.zip\n",
      "text_CR-jfy.zip\n",
      "text_HN-paj.zip\n",
      "text_GT-miv.zip\n",
      "text_PR-epz.zip\n",
      "text_CL-wts.zip\n",
      "text_PE-tae.zip\n",
      "text_PY-ukd.zip\n",
      "text_UY-nde.zip\n",
      "text_NI-exu.zip\n",
      "text_DO-egn.zip\n",
      "text_ES-sbo.zip\n",
      "text_PA-qlz.zip\n",
      "text_US-ufh.zip\n",
      "text_SV-xkl.zip\n",
      "text_CO-pem.zip\n",
      "text_BO-teh.zip\n",
      "text_VE-wsc.zip\n"
     ]
    }
   ],
   "source": [
    "# loads corpus as a dictionary\n",
    "\n",
    "raw_span = loadcorpus(\"data/SPAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the url where the texts come from as a list\n",
    "\n",
    "source_list = att_sources(\"data/SPAN\", \"span_sources.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_df = pd.DataFrame(columns=[\"Title\", \"Genre\", \"Country\",\n",
    "                                    \"Website\", \"URL\", \"Number of words\",\n",
    "                                    \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites_text = dic_match_key_text(raw_span, max_num_loops=10, max_texts=1000, max_onetext_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_df = merge_text_sources(source_list, websites_text, span_df, max_num_loops=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Country</th>\n",
       "      <th>Website</th>\n",
       "      <th>URL</th>\n",
       "      <th>Number of words</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389972</th>\n",
       "      <td>descubrecuador: Las Cascadas Verdes y la Casca...</td>\n",
       "      <td>b</td>\n",
       "      <td>EC</td>\n",
       "      <td>0latitud.blogspot.com</td>\n",
       "      <td>http://0latitud.blogspot.com/2010/01/las-casca...</td>\n",
       "      <td>294</td>\n",
       "      <td>Páginas martes  19 de enero de 2010 A unas dos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390030</th>\n",
       "      <td>Acoso textual: Vargas Llosa oye cantar el gall...</td>\n",
       "      <td>b</td>\n",
       "      <td>EC</td>\n",
       "      <td>acoso-textual.blogspot.com</td>\n",
       "      <td>http://acoso-textual.blogspot.com/2011/04/varg...</td>\n",
       "      <td>2114</td>\n",
       "      <td>( Fragmento de la obra Tardes de lluvia en el ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390040</th>\n",
       "      <td>MANABI ES....ECUADOR: LA CASA DE LOS CACHOS</td>\n",
       "      <td>b</td>\n",
       "      <td>EC</td>\n",
       "      <td>actividadesculturalesmanabi.blogspot.com</td>\n",
       "      <td>http://actividadesculturalesmanabi.blogspot.co...</td>\n",
       "      <td>245</td>\n",
       "      <td>En nuestro recorrido semanal por el basto terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390051</th>\n",
       "      <td>hoja almendro muy beneficiosa para nuestro acu...</td>\n",
       "      <td>b</td>\n",
       "      <td>EC</td>\n",
       "      <td>acuariovalhallafish.blogspot.com</td>\n",
       "      <td>http://acuariovalhallafish.blogspot.com/2011/0...</td>\n",
       "      <td>1699</td>\n",
       "      <td>acuario valhalla fish pone a su disposicion di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390052</th>\n",
       "      <td>ACUARIO VALHALLA FISH: carbon activo propiedad...</td>\n",
       "      <td>b</td>\n",
       "      <td>EC</td>\n",
       "      <td>acuariovalhallafish.blogspot.com</td>\n",
       "      <td>http://acuariovalhallafish.blogspot.com/2012/0...</td>\n",
       "      <td>1922</td>\n",
       "      <td>acuario valhalla fish pone a su disposición di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616129</th>\n",
       "      <td>Eloy Alfaro | AfroEcuatorianos</td>\n",
       "      <td>g</td>\n",
       "      <td>EC</td>\n",
       "      <td>afros.wordpress.com</td>\n",
       "      <td>http://afros.wordpress.com/historia/eloy-alfaro/</td>\n",
       "      <td>1351</td>\n",
       "      <td>Blogroll Categorías Comentarios ALFARO Y LOS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616139</th>\n",
       "      <td>Ritos Funerarios | AfroEcuatorianos</td>\n",
       "      <td>g</td>\n",
       "      <td>EC</td>\n",
       "      <td>afros.wordpress.com</td>\n",
       "      <td>http://afros.wordpress.com/religiosidad-afroec...</td>\n",
       "      <td>510</td>\n",
       "      <td>Blogroll Categorías Comentarios El hecho de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616149</th>\n",
       "      <td>Las 5 cosas de las que nos arrepentimos antes ...</td>\n",
       "      <td>g</td>\n",
       "      <td>EC</td>\n",
       "      <td>agustinsaga.com</td>\n",
       "      <td>http://agustinsaga.com/personas/las-5-cosas-de...</td>\n",
       "      <td>1001</td>\n",
       "      <td>Las 5 cosas de las que nos arrepentimos antes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616169</th>\n",
       "      <td>Democratizar la palabra - Alai</td>\n",
       "      <td>g</td>\n",
       "      <td>EC</td>\n",
       "      <td>alainet.org</td>\n",
       "      <td>http://alainet.org/publica/democom/</td>\n",
       "      <td>327</td>\n",
       "      <td>Democratizar la palabra Movimientos convergen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946491</th>\n",
       "      <td>10 Ejemplos de Oraciones de la Noche</td>\n",
       "      <td>g</td>\n",
       "      <td>MX</td>\n",
       "      <td>10ejemplos.com</td>\n",
       "      <td>http://10ejemplos.com/10-ejemplos-de-oraciones...</td>\n",
       "      <td>1186</td>\n",
       "      <td>El dedicar el último pensamiento de el día a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4221 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Title Genre Country  \\\n",
       "389972   descubrecuador: Las Cascadas Verdes y la Casca...     b      EC   \n",
       "390030   Acoso textual: Vargas Llosa oye cantar el gall...     b      EC   \n",
       "390040         MANABI ES....ECUADOR: LA CASA DE LOS CACHOS     b      EC   \n",
       "390051   hoja almendro muy beneficiosa para nuestro acu...     b      EC   \n",
       "390052   ACUARIO VALHALLA FISH: carbon activo propiedad...     b      EC   \n",
       "...                                                    ...   ...     ...   \n",
       "1616129                     Eloy Alfaro | AfroEcuatorianos     g      EC   \n",
       "1616139                Ritos Funerarios | AfroEcuatorianos     g      EC   \n",
       "1616149  Las 5 cosas de las que nos arrepentimos antes ...     g      EC   \n",
       "1616169                     Democratizar la palabra - Alai     g      EC   \n",
       "1946491               10 Ejemplos de Oraciones de la Noche     g      MX   \n",
       "\n",
       "                                          Website  \\\n",
       "389972                      0latitud.blogspot.com   \n",
       "390030                 acoso-textual.blogspot.com   \n",
       "390040   actividadesculturalesmanabi.blogspot.com   \n",
       "390051           acuariovalhallafish.blogspot.com   \n",
       "390052           acuariovalhallafish.blogspot.com   \n",
       "...                                           ...   \n",
       "1616129                       afros.wordpress.com   \n",
       "1616139                       afros.wordpress.com   \n",
       "1616149                           agustinsaga.com   \n",
       "1616169                               alainet.org   \n",
       "1946491                            10ejemplos.com   \n",
       "\n",
       "                                                       URL Number of words  \\\n",
       "389972   http://0latitud.blogspot.com/2010/01/las-casca...             294   \n",
       "390030   http://acoso-textual.blogspot.com/2011/04/varg...            2114   \n",
       "390040   http://actividadesculturalesmanabi.blogspot.co...             245   \n",
       "390051   http://acuariovalhallafish.blogspot.com/2011/0...            1699   \n",
       "390052   http://acuariovalhallafish.blogspot.com/2012/0...            1922   \n",
       "...                                                    ...             ...   \n",
       "1616129   http://afros.wordpress.com/historia/eloy-alfaro/            1351   \n",
       "1616139  http://afros.wordpress.com/religiosidad-afroec...             510   \n",
       "1616149  http://agustinsaga.com/personas/las-5-cosas-de...            1001   \n",
       "1616169                http://alainet.org/publica/democom/             327   \n",
       "1946491  http://10ejemplos.com/10-ejemplos-de-oraciones...            1186   \n",
       "\n",
       "                                                      Text  \n",
       "389972   Páginas martes  19 de enero de 2010 A unas dos...  \n",
       "390030   ( Fragmento de la obra Tardes de lluvia en el ...  \n",
       "390040   En nuestro recorrido semanal por el basto terr...  \n",
       "390051   acuario valhalla fish pone a su disposicion di...  \n",
       "390052   acuario valhalla fish pone a su disposición di...  \n",
       "...                                                    ...  \n",
       "1616129   Blogroll Categorías Comentarios ALFARO Y LOS ...  \n",
       "1616139   Blogroll Categorías Comentarios El hecho de l...  \n",
       "1616149   Las 5 cosas de las que nos arrepentimos antes...  \n",
       "1616169   Democratizar la palabra Movimientos convergen...  \n",
       "1946491   El dedicar el último pensamiento de el día a ...  \n",
       "\n",
       "[4221 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
